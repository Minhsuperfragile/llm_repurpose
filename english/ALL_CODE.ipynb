{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AI Content Repurposing Machine "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Work with python 3.12.7\n",
    "!pip install simplerllm streamlit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from SimplerLLM.tools.generic_loader import load_content\n",
    "from SimplerLLM.language.llm import LLM, LLMProvider\n",
    "from resources import text_to_x_thread, text_to_blog_post, text_to_medium_post, text_to_summary, text_to_newsletter, format_to_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os , json\n",
    "\n",
    "os.environ['GEMINI_API_KEY'] = \"AIzaSyDzUs85b_kCq4i850Uof05cEnNBqyArld8\" # Variable name is important, don't change it\n",
    "\n",
    "LLM_PROVIDER = LLMProvider.GEMINI\n",
    "LLM_NAME = 'gemini-pro'\n",
    "CONTENT_URL = \"https://arxiv.org/pdf/2402.06196\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This can take a youtube video link, a blog post link, a csv file, etc... as input too \n",
    "file = load_content(CONTENT_URL)\n",
    "\n",
    "#Edit the prompt name in accordance to what you want to convert it to\n",
    "final_prompt = text_to_summary.format(input = file.content) \n",
    "\n",
    "llm_instance = LLM.create(provider=LLM_PROVIDER,model_name=LLM_NAME)\n",
    "\n",
    "response = llm_instance.generate_response(prompt=final_prompt, max_tokens=1000)\n",
    "\n",
    "with open(\"response.txt\", \"w\", encoding='utf-8') as f:\n",
    "    f.write(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create 3 types of content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_instance = LLM.create(provider=LLM_PROVIDER, model_name=LLM_NAME)\n",
    "\n",
    "#This can take a youtube video link, a blog post link, a csv file, etc... as input too \n",
    "file = load_content(\"https://learnwithhasan.com/create-ai-agents-with-python/\") \n",
    "\n",
    "#Getting the 3 inputs\n",
    "x_prompt = text_to_x_thread.format(input = file.content) \n",
    "newsletter_prompt = text_to_newsletter.format(input = file.content) \n",
    "summary_prompt = text_to_summary.format(input = file.content) \n",
    "\n",
    "#Generating the 3 types of social posts\n",
    "x_thread = llm_instance.generate_response(prompt = x_prompt, max_tokens=1000)\n",
    "with open(\"twitter.txt\", \"w\", encoding='utf-8') as f:\n",
    "    f.write(x_thread)\n",
    "\n",
    "newsletter_section = llm_instance.generate_response(prompt = newsletter_prompt, max_tokens=1000)\n",
    "with open(\"newsletter.txt\", \"w\", encoding='utf-8') as f:\n",
    "    f.write(newsletter_section)\n",
    "\n",
    "bullet_point_summary = llm_instance.generate_response(prompt = summary_prompt, max_tokens=1000)\n",
    "with open(\"summary.txt\", \"w\", encoding='utf-8') as f:\n",
    "    f.write(bullet_point_summary)\n",
    "\n",
    "#Converting them into json format\n",
    "final_prompt = format_to_json.format(input_1 = x_thread, \n",
    "                                     input_2 = newsletter_section, \n",
    "                                     input_3 = bullet_point_summary) \n",
    "\n",
    "response = llm_instance.generate_response(prompt = final_prompt, max_tokens=3000)\n",
    "\n",
    "# Validate and write JSON with indentation for readability\n",
    "try:\n",
    "    json_data = json.loads(response)\n",
    "    with open(\"Json_Result.json\", \"w\", encoding='utf-8') as f:\n",
    "        json.dump(json_data, f, ensure_ascii=False, indent=4)\n",
    "    print(\"JSON saved successfully.\")\n",
    "except json.JSONDecodeError as e:\n",
    "    print(\"Error in JSON format:\", e)\n",
    "    with open(\"Json_Result.json\", \"w\", encoding='utf-8') as f:\n",
    "        f.write(response) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Streamlit web UI\n",
    "run with command:  \"streamlit run ui.py\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-16 16:00:55.205 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-12-16 16:00:55.258 \n",
      "  \u001b[33m\u001b[1mWarning:\u001b[0m to view this Streamlit app on a browser, run it with the following\n",
      "  command:\n",
      "\n",
      "    streamlit run /home/tminh/anaconda3/envs/llmft/lib/python3.12/site-packages/ipykernel_launcher.py [ARGUMENTS]\n",
      "2024-12-16 16:00:55.260 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-12-16 16:00:55.262 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-12-16 16:00:55.263 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-12-16 16:00:55.264 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-12-16 16:00:55.265 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-12-16 16:00:55.267 Session state does not function when running a script without `streamlit run`\n",
      "2024-12-16 16:00:55.268 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-12-16 16:00:55.270 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-12-16 16:00:55.272 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-12-16 16:00:55.273 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-12-16 16:00:55.274 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-12-16 16:00:55.276 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-12-16 16:00:55.277 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
     ]
    }
   ],
   "source": [
    "import streamlit as st\n",
    "import json\n",
    "from SimplerLLM.tools.generic_loader import load_content\n",
    "from SimplerLLM.language.llm import LLM, LLMProvider\n",
    "from resources import text_to_x_thread, text_to_summary, text_to_newsletter, format_to_json\n",
    "\n",
    "llm_instance = LLM.create(provider=LLM_PROVIDER, model_name=LLM_NAME)\n",
    "\n",
    "st.title(\"Content Generation With A Single Click\")\n",
    "\n",
    "url = st.text_input(\"Enter the URL or File Name of your input:\")\n",
    "\n",
    "if st.button(\"Generate Content\"):\n",
    "    if url:\n",
    "        try:\n",
    "            file = load_content(url)\n",
    "\n",
    "            x_prompt = text_to_x_thread.format(input=file.content)\n",
    "            newsletter_prompt = text_to_newsletter.format(input=file.content)\n",
    "            summary_prompt = text_to_summary.format(input=file.content)\n",
    "\n",
    "            x_thread = llm_instance.generate_response(prompt=x_prompt, max_tokens=1000)\n",
    "            newsletter_section = llm_instance.generate_response(prompt=newsletter_prompt, max_tokens=1000)\n",
    "            bullet_point_summary = llm_instance.generate_response(prompt=summary_prompt, max_tokens=1000)\n",
    "\n",
    "            st.subheader(\"Generated Twitter Thread\")\n",
    "            st.write(x_thread)\n",
    "            st.markdown(\"---\")\n",
    "\n",
    "            st.subheader(\"Generated Newsletter Section\")\n",
    "            st.write(newsletter_section)\n",
    "            st.markdown(\"---\")\n",
    "\n",
    "            st.subheader(\"Generated Bullet Point Summary\")\n",
    "            st.write(bullet_point_summary)\n",
    "            st.markdown(\"---\")\n",
    "\n",
    "            final_prompt = format_to_json.format(\n",
    "                input_1=x_thread, \n",
    "                input_2=newsletter_section, \n",
    "                input_3=bullet_point_summary\n",
    "            )\n",
    "            response = llm_instance.generate_response(prompt=final_prompt, max_tokens=3000)\n",
    "            \n",
    "            try:\n",
    "                json_data = json.loads(response)\n",
    "                st.markdown(\"### __Generated JSON Result__\")\n",
    "                st.json(json_data)\n",
    "                st.download_button(\n",
    "                    label=\"Download JSON Result\",\n",
    "                    data=json.dumps(json_data, ensure_ascii=False, indent=4),\n",
    "                    file_name=\"Json_Result.json\",\n",
    "                    mime=\"application/json\"\n",
    "                )\n",
    "            except json.JSONDecodeError as e:\n",
    "                st.error(f\"Error in JSON format: {e}\")\n",
    "                st.write(response)\n",
    "        except Exception as e:\n",
    "            st.error(f\"An error occurred: {e}\")\n",
    "    else:\n",
    "        st.warning(\"Please enter a valid URL.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llmft",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
